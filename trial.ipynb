{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c82cb7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\GR Thasshien\\Documents\\Dataset\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from pymongo import MongoClient\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "import fitz\n",
    "import os\n",
    "import io\n",
    "from docx import Document\n",
    "import regex as re\n",
    "import ollama\n",
    "import json\n",
    "client = MongoClient(\"mongodb+srv://daktrboys05_db_user:gdgclubproject@to-do-list.qmqixqe.mongodb.net/\")\n",
    "db = client[\"tries_db\"]\n",
    "questions_collection = db[\"questions\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82f6708",
   "metadata": {},
   "source": [
    "FOR UPDATING DB WITH ANSWER KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a268f920",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"test.pdf\"\n",
    "answer_file_path = \"test_answer.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f6e7ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_docx(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    collected = []\n",
    "\n",
    "    # Body paragraphs\n",
    "    for para in doc.paragraphs:\n",
    "        text = para.text.strip()\n",
    "        if text:\n",
    "            collected.append(text)\n",
    "\n",
    "    # Tables\n",
    "    for table in doc.tables:\n",
    "        for row in table.rows:\n",
    "            for cell in row.cells:\n",
    "                cell_text = cell.text.strip()\n",
    "                if cell_text:\n",
    "                    collected.append(cell_text)\n",
    "\n",
    "    # Headers & footers\n",
    "    for section in doc.sections:\n",
    "        header = section.header\n",
    "        footer = section.footer\n",
    "\n",
    "        for para in header.paragraphs:\n",
    "            if para.text.strip():\n",
    "                collected.append(para.text.strip())\n",
    "\n",
    "        for para in footer.paragraphs:\n",
    "            if para.text.strip():\n",
    "                collected.append(para.text.strip())\n",
    "\n",
    "    # Embedded images → OCR\n",
    "    for rel in doc.part.rels.values():\n",
    "        if \"image\" in rel.target_ref:\n",
    "            image_bytes = rel.target_part.blob\n",
    "            img = Image.open(io.BytesIO(image_bytes))\n",
    "            ocr_text = pytesseract.image_to_string(\n",
    "                img,\n",
    "                lang=\"eng\",\n",
    "                config=\"--psm 6\"\n",
    "            )\n",
    "            if ocr_text.strip():\n",
    "                collected.append(ocr_text.strip())\n",
    "\n",
    "    return \"\\n\".join(collected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00b2b397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    texts = []\n",
    "\n",
    "    for page_num, page in enumerate(doc):\n",
    "        # Digital text\n",
    "        page_text = page.get_text().strip()\n",
    "        if page_text:\n",
    "            texts.append(page_text)\n",
    "\n",
    "        # OCR embedded images\n",
    "        images = page.get_images(full=True)\n",
    "        for img in images:\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "\n",
    "            img_pil = Image.open(io.BytesIO(image_bytes))\n",
    "            ocr_text = pytesseract.image_to_string(\n",
    "                img_pil,\n",
    "                lang=\"eng\",\n",
    "                config=\"--psm 6\"\n",
    "            ).strip()\n",
    "\n",
    "            if ocr_text:\n",
    "                texts.append(ocr_text)\n",
    "\n",
    "        # Full-page OCR fallback\n",
    "        if not page_text and not images:\n",
    "            pix = page.get_pixmap(dpi=300)\n",
    "            img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "            ocr_text = pytesseract.image_to_string(img, lang=\"eng\").strip()\n",
    "\n",
    "            if ocr_text:\n",
    "                texts.append(ocr_text)\n",
    "\n",
    "    return texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cea72a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_image(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    return pytesseract.image_to_string(img).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072a1570",
   "metadata": {},
   "source": [
    "SPLITTING FOR TEXT FROM ANSWER KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b747a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_questions(text: str) -> list[str]:\n",
    "    \n",
    "    pattern = (\n",
    "        r\"(\\[\\d+\\s*marks?\\]\\s*Question:.*?)(?=\\[\\d+\\s*marks?\\]\\s*Question:|$)\"\n",
    "    )\n",
    "    matches = re.findall(pattern, text, flags=re.IGNORECASE | re.DOTALL)\n",
    "\n",
    "    question_blocks = []\n",
    "    for idx, block in enumerate(matches, start=1):\n",
    "        question_blocks.append(\n",
    "            f\"[QUESTION_{idx}_START]\\n{block.strip()}\"\n",
    "        )\n",
    "    return question_blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a321452d",
   "metadata": {},
   "source": [
    "SPLITTING FOR TEXT FROM ANSWERS BY STUDENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eaaeeff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_answers(text: str) -> list[str]:\n",
    "    pattern = r\"(Question\\s+\\d+[\\s\\S]*?)(?=Question\\s+\\d+|$)\"\n",
    "    matches = re.findall(pattern, text, flags=re.IGNORECASE)\n",
    "\n",
    "    answer_blocks = []\n",
    "    for idx, block in enumerate(matches, start=1):\n",
    "        answer_blocks.append(\n",
    "            f\"[ANSWER_{idx}_START]\\n{block.strip()}\"\n",
    "        )\n",
    "\n",
    "    return answer_blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d2c626",
   "metadata": {},
   "source": [
    "FUNCTION TO EXTRACT TEXT FROM ANSWER KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da36d483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(file_path):\n",
    "    ext = os.path.splitext(file_path)[1].lower()\n",
    "\n",
    "    if ext == \".pdf\":\n",
    "        pdf_texts = extract_text_from_pdf(file_path)\n",
    "        full_text = \"\\n\".join(pdf_texts)\n",
    "        return split_by_questions(full_text)\n",
    "    \n",
    "    elif ext == \".docx\":\n",
    "        return (list(extract_text_from_docx(file_path)))\n",
    "\n",
    "    elif ext in [\".png\", \".jpg\", \".jpeg\"]:\n",
    "        return (list(extract_text_from_image(file_path)))\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cf57f6",
   "metadata": {},
   "source": [
    "FUNCTION TO EXTRACT TEXT FROM STUDENT ANSWERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30a3a6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_student_text(answer_file_path):\n",
    "    ext = os.path.splitext(answer_file_path)[1].lower()\n",
    "\n",
    "    if ext == \".pdf\":\n",
    "        pdf_texts = extract_text_from_pdf(answer_file_path)\n",
    "        full_text = \"\\n\".join(pdf_texts)\n",
    "        return split_by_answers(full_text)\n",
    "\n",
    "    elif ext == \".docx\":\n",
    "        full_text = extract_text_from_docx(answer_file_path)\n",
    "        return split_by_answers(full_text)\n",
    "\n",
    "    elif ext in [\".png\", \".jpg\", \".jpeg\"]:\n",
    "        full_text = extract_text_from_image(answer_file_path)\n",
    "        return split_by_answers(full_text)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b45af6",
   "metadata": {},
   "source": [
    "CHUNKING THE EXTRACTED TEXT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f77981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class embeddingManager:\n",
    "  def __init__(self,model_name : str = \"all-MiniLM-L6-v2\"):\n",
    "    #hugging face model for sentence embedding\n",
    "    self.model_name = model_name\n",
    "    self.model = None\n",
    "    self._load_model()\n",
    "\n",
    "  def _load_model(self):\n",
    "    try:\n",
    "      print(f\"Loading embedding model: {self.model_name}\")\n",
    "      self.model = SentenceTransformer(self.model_name)\n",
    "      print(f\"Embedding model loaded successfully.Embedding dimension: {self.model.get_sentence_embedding_dimension()}\")\n",
    "    except Exception as e:\n",
    "      print(f\"Error loading embedding model: {e}\")\n",
    "\n",
    "  def generate_embeddings(self,texts:list[str]) -> np.ndarray:#returns numpy array\n",
    "    if self.model is None:\n",
    "      self._load_model()\n",
    "    print(f\"Generating embedding for {len(texts)} texts....\")\n",
    "    embeddings = self.model.encode(texts, show_progress_bar = True)\n",
    "    print(\"Embedding generated successfully.\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09101e40",
   "metadata": {},
   "source": [
    "EMBEDDING FOR ANSWER KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cfc96eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: all-MiniLM-L6-v2\n",
      "Embedding model loaded successfully.Embedding dimension: 384\n",
      "number of records:  6\n",
      "extracted texts: ['[QUESTION_1_START]\\n[10 marks]\\nQuestion: Explain the concept of ACID properties in database transactions. Discuss how each property ensures data\\nconsistency and provide real-world scenarios where violation of these properties could lead to problems.\\nEvaluation Rubric:\\nTrait\\nWeight\\nDescription\\nConcept Coverage\\n40%\\nComprehensive explanation of all 4 ACID properties (Atomicity, Consistency, Isolation\\nReal-World Application\\n30%\\nClear examples of transactions and scenarios where violations cause problems\\nLogical Flow\\n20%\\nWell-organized answer with clear connections between properties\\nClarity & Language\\n10%\\nClear writing, appropriate terminology usage\\nQuestion 2', '[QUESTION_2_START]\\n[8 marks]\\nQuestion: Write a SQL query to find the top 5 departments by average salary, excluding departments with fewer than\\n10 employees. Include department name and average salary in results.\\nExpected Answer:\\nSELECT d.dept_name, AVG(e.salary) AS avg_salary\\nFROM departments d\\nINNER JOIN employees e ON d.dept_id = e.dept_id\\nGROUP BY d.dept_id, d.dept_name\\nHAVING COUNT(e.emp_id) >= 10\\nORDER BY avg_salary DESC\\nLIMIT 5;\\nKey Points:\\n• Correct JOIN syntax connecting departments and employees tables\\n• GROUP BY clause with both dept_id and dept_name\\n• HAVING clause for filtering groups by employee count (COUNT >= 10)\\n• ORDER BY with DESC for descending average salary\\n• LIMIT 5 to restrict result set\\n• Correct aggregation function AVG()\\nQuestion 3', '[QUESTION_3_START]\\n[12 marks]\\nQuestion: Discuss the differences between supervised and unsupervised learning. Provide at least two examples for\\neach category and explain why certain problem types are better suited to each approach.\\nEvaluation Rubric:\\nTrait\\nWeight\\nDescription\\nFundamental Differences\\n35%\\nClear explanation of labeled vs unlabeled data, training approach differences\\nExamples Provided\\n35%\\nMinimum 2 valid examples each (supervised: classification, regression; unsupervised:\\nProblem Suitability Analysis\\n20%\\nReasoning for why certain problems fit each approach\\nOrganization & Clarity\\n10%\\nWell-structured response with clear delineation between sections\\nQuestion 4', '[QUESTION_4_START]\\n[7 marks]\\nQuestion: Given an array of integers, implement an algorithm to find if there exists a subarray with sum equal to a\\ntarget value. Time complexity should not exceed O(n).\\nExpected Answer Approach:\\ndef find_subarray_sum(arr, target):\\n    seen_sums = {0} # Set to track cumulative sums\\n    current_sum = 0\\n    \\n    for num in arr:\\n        current_sum += num\\n        if (current_sum - target) in seen_sums:\\n            return True\\n        seen_sums.add(current_sum)\\n    return False\\nKey Points:\\n• Use of hash set/dictionary for O(1) lookup of cumulative sums\\n• Cumulative sum approach to track running total\\n• Logic: if (current_sum - target) exists, then subarray found\\n• Single pass through array = O(n) time complexity\\n• O(n) space complexity for set storage\\n• Handles negative numbers and edge cases\\n• Alternative: Sliding window for positive integers only\\nQuestion 5', '[QUESTION_5_START]\\n[9 marks]\\nQuestion: Analyze the impact of network latency and bandwidth constraints on distributed system design. How would\\nyou architect a system to handle high-latency and low-bandwidth environments?\\nEvaluation Rubric:\\nTrait\\nWeight\\nDescription\\nImpact Analysis\\n30%\\nExplanation of latency/bandwidth effects on system performance and reliability\\nDesign Strategies\\n40%\\nMultiple strategies (caching, compression, async communication, local processing, bat\\nTrade-offs Discussion\\n20%\\nUnderstanding of consistency vs performance trade-offs\\nCoherence & Examples\\n10%\\nWell-articulated with practical examples\\nQuestion 6', '[QUESTION_6_START]\\n[6 marks]\\nQuestion: Write a MongoDB aggregation pipeline to calculate the monthly revenue for each product category, sorting\\nby revenue in descending order.\\nExpected Answer:\\ndb.orders.aggregate([\\n    {\\n        $group: {\\n_id: {\\n                category: \"$product.category\",\\n                month: { $dateToString: { format: \"%Y-%m\", date: \"$order_date\" } }\\n            },\\n            monthly_revenue: { $sum: \"$total_amount\" }\\n        }\\n    },\\n    {\\n        $sort: { monthly_revenue: -1 }\\n    }\\n])\\nKey Points:\\n• Correct $group stage with nested _id for category and month\\n• $dateToString for formatting date to YYYY-MM format\\n• $sum aggregation to calculate total revenue\\n• $sort stage with -1 for descending order\\n• Proper MongoDB syntax and nested field access ($product.category)\\n• Handles multiple documents per category-month combination\\n• Alternative: Using $month and $year functions instead of $dateToString\\nGRADING GUIDELINES\\nQuestion\\nType\\nMax Marks\\nGrading Method\\n1\\nDESCRIPTIVE\\n10\\nRubric-based with weighted traits\\n2\\nTECHNICAL\\n8\\nCorrectness + Code quality + Keywords\\n3\\nDESCRIPTIVE\\n12\\nRubric-based with weighted traits\\n4\\nTECHNICAL\\n7\\nAlgorithm correctness + Complexity analysis\\n5\\nDESCRIPTIVE\\n9\\nRubric-based with weighted traits\\n6\\nTECHNICAL\\n6\\nQuery correctness + Syntax + Stage usage\\n<b>Total: 52</b>\\nNote: This answer key is for instructor reference only. Students should demonstrate understanding of concepts, proper methodology, and clear\\ncommunication. Partial credit may be awarded for partially correct answers.']\n",
      "starts: [QUESTION_1_START]\n",
      "[10 marks]\n",
      "Question: Explain the concept of ACID properties in database transactions. Discuss how each property ensures data\n",
      "consistency and provide real-world scenarios where violation of these properties could lead to problems.\n",
      "Evaluation Rubric:\n",
      "Trait\n",
      "Weight\n",
      "Description\n",
      "Concept Coverage\n",
      "40%\n",
      "Comprehensive explanation of all 4 ACID properties (Atomicity, Consistency, Isolation\n",
      "Real-World Application\n",
      "30%\n",
      "Clear examples of transactions and scenarios where violations cause problems\n",
      "Logical Flow\n",
      "20%\n",
      "Well-organized answer with clear connections between properties\n",
      "Clarity & Language\n",
      "10%\n",
      "Clear writing, appropriate terminology usage\n",
      "Question 2\n",
      "\n",
      "\n",
      "starts: [QUESTION_2_START]\n",
      "[8 marks]\n",
      "Question: Write a SQL query to find the top 5 departments by average salary, excluding departments with fewer than\n",
      "10 employees. Include department name and average salary in results.\n",
      "Expected Answer:\n",
      "SELECT d.dept_name, AVG(e.salary) AS avg_salary\n",
      "FROM departments d\n",
      "INNER JOIN employees e ON d.dept_id = e.dept_id\n",
      "GROUP BY d.dept_id, d.dept_name\n",
      "HAVING COUNT(e.emp_id) >= 10\n",
      "ORDER BY avg_salary DESC\n",
      "LIMIT 5;\n",
      "Key Points:\n",
      "• Correct JOIN syntax connecting departments and employees tables\n",
      "• GROUP BY clause with both dept_id and dept_name\n",
      "• HAVING clause for filtering groups by employee count (COUNT >= 10)\n",
      "• ORDER BY with DESC for descending average salary\n",
      "• LIMIT 5 to restrict result set\n",
      "• Correct aggregation function AVG()\n",
      "Question 3\n",
      "\n",
      "\n",
      "starts: [QUESTION_3_START]\n",
      "[12 marks]\n",
      "Question: Discuss the differences between supervised and unsupervised learning. Provide at least two examples for\n",
      "each category and explain why certain problem types are better suited to each approach.\n",
      "Evaluation Rubric:\n",
      "Trait\n",
      "Weight\n",
      "Description\n",
      "Fundamental Differences\n",
      "35%\n",
      "Clear explanation of labeled vs unlabeled data, training approach differences\n",
      "Examples Provided\n",
      "35%\n",
      "Minimum 2 valid examples each (supervised: classification, regression; unsupervised:\n",
      "Problem Suitability Analysis\n",
      "20%\n",
      "Reasoning for why certain problems fit each approach\n",
      "Organization & Clarity\n",
      "10%\n",
      "Well-structured response with clear delineation between sections\n",
      "Question 4\n",
      "\n",
      "\n",
      "starts: [QUESTION_4_START]\n",
      "[7 marks]\n",
      "Question: Given an array of integers, implement an algorithm to find if there exists a subarray with sum equal to a\n",
      "target value. Time complexity should not exceed O(n).\n",
      "Expected Answer Approach:\n",
      "def find_subarray_sum(arr, target):\n",
      "    seen_sums = {0} # Set to track cumulative sums\n",
      "    current_sum = 0\n",
      "    \n",
      "    for num in arr:\n",
      "        current_sum += num\n",
      "        if (current_sum - target) in seen_sums:\n",
      "            return True\n",
      "        seen_sums.add(current_sum)\n",
      "    return False\n",
      "Key Points:\n",
      "• Use of hash set/dictionary for O(1) lookup of cumulative sums\n",
      "• Cumulative sum approach to track running total\n",
      "• Logic: if (current_sum - target) exists, then subarray found\n",
      "• Single pass through array = O(n) time complexity\n",
      "• O(n) space complexity for set storage\n",
      "• Handles negative numbers and edge cases\n",
      "• Alternative: Sliding window for positive integers only\n",
      "Question 5\n",
      "\n",
      "\n",
      "starts: [QUESTION_5_START]\n",
      "[9 marks]\n",
      "Question: Analyze the impact of network latency and bandwidth constraints on distributed system design. How would\n",
      "you architect a system to handle high-latency and low-bandwidth environments?\n",
      "Evaluation Rubric:\n",
      "Trait\n",
      "Weight\n",
      "Description\n",
      "Impact Analysis\n",
      "30%\n",
      "Explanation of latency/bandwidth effects on system performance and reliability\n",
      "Design Strategies\n",
      "40%\n",
      "Multiple strategies (caching, compression, async communication, local processing, bat\n",
      "Trade-offs Discussion\n",
      "20%\n",
      "Understanding of consistency vs performance trade-offs\n",
      "Coherence & Examples\n",
      "10%\n",
      "Well-articulated with practical examples\n",
      "Question 6\n",
      "\n",
      "\n",
      "starts: [QUESTION_6_START]\n",
      "[6 marks]\n",
      "Question: Write a MongoDB aggregation pipeline to calculate the monthly revenue for each product category, sorting\n",
      "by revenue in descending order.\n",
      "Expected Answer:\n",
      "db.orders.aggregate([\n",
      "    {\n",
      "        $group: {\n",
      "_id: {\n",
      "                category: \"$product.category\",\n",
      "                month: { $dateToString: { format: \"%Y-%m\", date: \"$order_date\" } }\n",
      "            },\n",
      "            monthly_revenue: { $sum: \"$total_amount\" }\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        $sort: { monthly_revenue: -1 }\n",
      "    }\n",
      "])\n",
      "Key Points:\n",
      "• Correct $group stage with nested _id for category and month\n",
      "• $dateToString for formatting date to YYYY-MM format\n",
      "• $sum aggregation to calculate total revenue\n",
      "• $sort stage with -1 for descending order\n",
      "• Proper MongoDB syntax and nested field access ($product.category)\n",
      "• Handles multiple documents per category-month combination\n",
      "• Alternative: Using $month and $year functions instead of $dateToString\n",
      "GRADING GUIDELINES\n",
      "Question\n",
      "Type\n",
      "Max Marks\n",
      "Grading Method\n",
      "1\n",
      "DESCRIPTIVE\n",
      "10\n",
      "Rubric-based with weighted traits\n",
      "2\n",
      "TECHNICAL\n",
      "8\n",
      "Correctness + Code quality + Keywords\n",
      "3\n",
      "DESCRIPTIVE\n",
      "12\n",
      "Rubric-based with weighted traits\n",
      "4\n",
      "TECHNICAL\n",
      "7\n",
      "Algorithm correctness + Complexity analysis\n",
      "5\n",
      "DESCRIPTIVE\n",
      "9\n",
      "Rubric-based with weighted traits\n",
      "6\n",
      "TECHNICAL\n",
      "6\n",
      "Query correctness + Syntax + Stage usage\n",
      "<b>Total: 52</b>\n",
      "Note: This answer key is for instructor reference only. Students should demonstrate understanding of concepts, proper methodology, and clear\n",
      "communication. Partial credit may be awarded for partially correct answers.\n",
      "\n",
      "\n",
      "Generating embedding for 6 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generated successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.01815865,  0.03243175, -0.08225077, ...,  0.04441799,\n",
       "         0.02949115, -0.05169402],\n",
       "       [ 0.01402685,  0.04991702,  0.10901149, ..., -0.08241593,\n",
       "        -0.01403602,  0.08955504],\n",
       "       [-0.00900713, -0.00058494, -0.02288687, ...,  0.06090765,\n",
       "        -0.02194507,  0.0628505 ],\n",
       "       [-0.0082739 ,  0.03229178, -0.04765171, ..., -0.06478573,\n",
       "        -0.04062334,  0.03412547],\n",
       "       [ 0.05345527,  0.08826678, -0.02615643, ...,  0.0467669 ,\n",
       "        -0.07550272,  0.01124337],\n",
       "       [ 0.01976677,  0.10287796,  0.00367258, ..., -0.1330917 ,\n",
       "        -0.05959409, -0.00589298]], shape=(6, 384), dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_manager = embeddingManager()\n",
    "texts = extract_text(file_path)\n",
    "print(\"number of records: \",len(texts))\n",
    "print(\"extracted texts:\", texts)\n",
    "for text in texts:\n",
    "    print(\"starts:\",text)\n",
    "    print(\"\\n\")\n",
    "embedding_manager.generate_embeddings(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b10f2d4",
   "metadata": {},
   "source": [
    "EMBEDDING FOR ANSWERS FROM STUDENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "764371dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: all-MiniLM-L6-v2\n",
      "Embedding model loaded successfully.Embedding dimension: 384\n"
     ]
    }
   ],
   "source": [
    "embedding_manager = embeddingManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24c1cca",
   "metadata": {},
   "source": [
    "GRADING TECHNICAL QUESTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "531bbde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_fallback(question, student_answer, embedding_manager) -> int:\n",
    "    \"\"\"\n",
    "    Fallback scoring using semantic similarity\n",
    "    when rubric config or LLM grading fails.\n",
    "    \"\"\"\n",
    "\n",
    "    if not student_answer.strip():\n",
    "        return 0\n",
    "\n",
    "    student_emb = embedding_manager.generate_embeddings([student_answer])\n",
    "    anchor_emb = embedding_manager.generate_embeddings([question[\"question_text\"]])\n",
    "\n",
    "    similarity = cosine_similarity(student_emb, anchor_emb)[0][0]\n",
    "\n",
    "    max_marks = question[\"max_marks\"]\n",
    "\n",
    "    # Convert similarity → marks\n",
    "    score = int(similarity * max_marks)\n",
    "\n",
    "    # Safety floor so good answers never get 0\n",
    "    if score == 0:\n",
    "        score = max(1, int(0.3 * max_marks))\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f72b9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_score(student_answer: str, keywords: list[str]) -> float:\n",
    "    if not keywords:\n",
    "        return 0.0\n",
    "\n",
    "    text = student_answer.lower()\n",
    "    hits = sum(1 for kw in keywords if kw.lower() in text)\n",
    "    return hits / len(keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5117670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solution_chunk_score(\n",
    "    student_answer: str,\n",
    "    solution_chunks: list[str],\n",
    "    embedding_manager\n",
    ") -> float:\n",
    "\n",
    "    if not solution_chunks:\n",
    "        return 0.0\n",
    "\n",
    "    student_emb = embedding_manager.generate_embeddings([student_answer])[0]\n",
    "\n",
    "    matched = 0\n",
    "    for chunk in solution_chunks:\n",
    "        chunk_emb = embedding_manager.generate_embeddings([chunk])[0]\n",
    "        sim = cosine_similarity([student_emb], [chunk_emb])[0][0]\n",
    "\n",
    "        if sim >= 0.65:   # semantic threshold\n",
    "            matched += 1\n",
    "\n",
    "    return matched / len(solution_chunks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0af1b594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_rule_score(student_answer: str, numeric_rules: dict) -> float:\n",
    "    if not numeric_rules:\n",
    "        return 0.0\n",
    "\n",
    "    expected_numbers = numeric_rules.get(\"expected_numbers\", [])\n",
    "\n",
    "    if not expected_numbers:\n",
    "        return 1.0   # nothing expected → full marks\n",
    "\n",
    "    text = student_answer.lower()\n",
    "    matched = 0\n",
    "\n",
    "    for num in expected_numbers:\n",
    "        if str(num).lower() in text:\n",
    "            matched += 1\n",
    "\n",
    "    return matched / len(expected_numbers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0850bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_similarity_score(\n",
    "    student_answer: str,\n",
    "    model_answer: str,\n",
    "    embedding_manager\n",
    ") -> float:\n",
    "\n",
    "    student_emb = embedding_manager.generate_embeddings([student_answer])\n",
    "    model_emb = embedding_manager.generate_embeddings([model_answer])\n",
    "\n",
    "    return cosine_similarity(student_emb, model_emb)[0][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6d5fcf",
   "metadata": {},
   "source": [
    "GRADING WITH LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4adad5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_technical_question(\n",
    "    student_answer: str,\n",
    "    technical_config: dict,\n",
    "    embedding_manager,\n",
    "    max_marks: int\n",
    ") -> int:\n",
    "\n",
    "    # 1. Semantic similarity\n",
    "    semantic_score = semantic_similarity_score(\n",
    "        student_answer,\n",
    "        technical_config[\"model_answer\"],\n",
    "        embedding_manager\n",
    "    )\n",
    "\n",
    "    # 2. Solution chunk coverage\n",
    "    chunk_score = solution_chunk_score(\n",
    "        student_answer,\n",
    "        technical_config.get(\"solution_chunks\", []),\n",
    "        embedding_manager\n",
    "    )\n",
    "\n",
    "    # 3. Keyword coverage\n",
    "    kw_score = keyword_score(\n",
    "        student_answer,\n",
    "        technical_config.get(\"keywords\", [])\n",
    "    )\n",
    "\n",
    "    # 4. Numeric / rule-based score\n",
    "    numeric_score = numeric_rule_score(\n",
    "        student_answer,\n",
    "        technical_config.get(\"numeric_rules\", {})\n",
    "    )\n",
    "\n",
    "    # Final weighted score\n",
    "    final_score = (\n",
    "        0.4 * semantic_score +\n",
    "        0.3 * chunk_score +\n",
    "        0.2 * kw_score +\n",
    "        0.1 * numeric_score\n",
    "    ) * max_marks\n",
    "\n",
    "    return round(final_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f5e3915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_descriptive_question(\n",
    "    question: dict,\n",
    "    student_answer: str,\n",
    "    embedding_manager\n",
    ") -> int:\n",
    "\n",
    "    print(\"Grading descriptive question...\")\n",
    "\n",
    "    max_marks = question[\"max_marks\"]\n",
    "\n",
    "    descriptive_cfg = question.get(\"descriptive_config\")\n",
    "    if descriptive_cfg is None:\n",
    "        print(\"⚠️ descriptive_config missing → semantic fallback\")\n",
    "        return semantic_fallback(question, student_answer, embedding_manager)\n",
    "\n",
    "    rubric = descriptive_cfg.get(\"rubric\")\n",
    "    if not rubric:\n",
    "        print(\"⚠️ rubric missing → semantic fallback\")\n",
    "        return semantic_fallback(question, student_answer, embedding_manager)\n",
    "\n",
    "    if not student_answer.strip():\n",
    "        return 0\n",
    "\n",
    "    rubric_prompt = \"\"\n",
    "    trait_max_map = {}\n",
    "\n",
    "    for r in rubric:\n",
    "        trait = r[\"trait\"]\n",
    "        trait_marks = round(r[\"weight\"] * max_marks)\n",
    "        trait_max_map[trait] = trait_marks\n",
    "\n",
    "        rubric_prompt += f\"\"\"\n",
    "Trait: {trait}\n",
    "Max Marks: {trait_marks}\n",
    "Description: {r['description']}\n",
    "\"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are an experienced university examiner.\n",
    "\n",
    "Evaluate the student answer STRICTLY using the rubric below.\n",
    "\n",
    "Question:\n",
    "{question['question_text']}\n",
    "\n",
    "Rubric (use ONLY these traits and max marks):\n",
    "{rubric_prompt}\n",
    "\n",
    "Student Answer:\n",
    "{student_answer}\n",
    "\n",
    "SCORING RULES:\n",
    "- Assign INTEGER marks only.\n",
    "- Score each trait independently.\n",
    "- Use values from 0 up to Max Marks.\n",
    "- Partial credit is allowed.\n",
    "- Do NOT invent traits.\n",
    "- If the answer meaningfully addresses a trait, award non-zero marks.\n",
    "\n",
    "OUTPUT FORMAT (STRICT JSON ONLY):\n",
    "{{\n",
    "  \"scores\": {{\n",
    "    \"<trait_name>\": <integer_marks>\n",
    "  }}\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = ollama.generate(\n",
    "            model=\"llama3:latest\",\n",
    "            prompt=prompt.strip()\n",
    "        )\n",
    "\n",
    "        data = json.loads(response[\"response\"])\n",
    "        scores = data.get(\"scores\", {})\n",
    "\n",
    "        total = 0\n",
    "        for trait, max_trait_marks in trait_max_map.items():\n",
    "            awarded = int(scores.get(trait, 0))\n",
    "            awarded = max(0, min(awarded, max_trait_marks))\n",
    "            total += awarded\n",
    "\n",
    "        return min(total, max_marks)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"⚠️ LLM failed:\", e)\n",
    "        return semantic_fallback(question, student_answer, embedding_manager)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49573611",
   "metadata": {},
   "source": [
    "FETCHING FROM BACKEND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8dced254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_question(exam_id: str, question_number: int):\n",
    "    question = questions_collection.find_one(\n",
    "        {\n",
    "            \"exam_id\": exam_id,\n",
    "            \"question_number\": question_number\n",
    "        },\n",
    "        {\n",
    "            \"_id\": 0\n",
    "        }\n",
    "    )\n",
    "    return question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81bf5e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted student answers: ['[ANSWER_1_START]\\nQuestion 1\\nAnswer:\\nDatabase transactions are governed by the ACID properties to ensure reliability and data integrity.\\nThese properties are Atomicity, Consistency, Isolation, and Durability.\\n1. Atomicity: This property ensures that a transaction is treated as a single unit of work. Either all\\nsteps in the transaction complete successfully, or none of them do. If a failure occurs during the\\ntransaction, the database is rolled back to its state before the transaction started.\\nReal-world violation: Consider a bank transfer where money is deducted from Account A but the system\\ncrashes before adding it to Account B. Without atomicity, the money simply vanishes. Atomicity\\nensures that if the credit fails, the debit is rolled back.\\n2. Consistency: This ensures that a transaction brings the database from one valid state to another,\\nmaintaining all defined rules, constraints, and cascades.\\nReal-world violation: If a database requires every employee to belong to a valid department, a violation\\noccurs if a transaction adds an employee with a non-existent department ID. Consistency prevents this\\ntransaction from committing.\\n3. Isolation: This property ensures that concurrent transactions occur independently without\\ninterference. The intermediate state of a transaction should not be visible to other transactions until it is\\ncommitted.\\nReal-world violation: In an e-commerce inventory system, if two customers buy the last item\\nsimultaneously, a lack of isolation could allow both to \"purchase\" the item, leading to a negative\\ninventory count (a race condition).\\n4. Durability: Once a transaction is committed, it remains committed even in the event of a system\\nfailure (e.g., power outage). The changes are permanently saved.\\nReal-world violation: A user receives a \"Purchase Successful\" message, but the server reboots\\nimmediately after. If the data wasn\\'t written to non-volatile storage (disk), the purchase record is lost,\\nyet the user believes it was successful.', '[ANSWER_2_START]\\nQuestion 2\\nSELECT d.dept_name, AVG(e.salary) AS avg_salary\\nFROM departments d\\nINNER JOIN employees e ON d.dept_id = e.dept_id\\nGROUP BY d.dept_id, d.dept_name\\nHAVING COUNT(e.emp_id) >= 10\\nORDER BY avg_salary DESC\\nLIMIT 5;', '[ANSWER_3_START]\\nQuestion 3\\nAnswer:\\nDifferences between Supervised and Unsupervised Learning\\nThe fundamental difference between these two paradigms lies in the nature of the data and the goal of\\nthe training. Supervised learning utilizes labeled data, where the algorithm is trained on input-output\\npairs. The model learns a function that maps inputs to desired outputs. In contrast, unsupervised\\nlearning deals with unlabeled data. The algorithm must explore the data structure on its own to find\\nhidden patterns or groupings without explicit instructions on what the output should look like.\\nExamples and Problem Suitability\\n1. Supervised Learning:\\n* Examples: Classification (Email Spam Detection) and Regression (Predicting House Prices).\\n* Suitability: This approach is best suited for problems where historical data is available with known\\noutcomes, and the goal is to predict outcomes for new, unforeseen data.\\n2. Unsupervised Learning:\\n* Examples: Clustering (Customer Segmentation) and Association (Market Basket Analysis).\\n* Suitability: This approach is ideal for exploratory analysis when the ground truth is unknown. It works\\nbest for discovering structure within data, such as anomaly detection or reducing the dimensionality of\\ncomplex datasets.', '[ANSWER_4_START]\\nQuestion 4\\nAnswer:\\nTo solve this in linear time O(n), I will use a hash set to store cumulative sums. If the difference\\nbetween the current cumulative sum and the target value exists in the set, a subarray with the specific\\nsum exists.\\ndef find_subarray_sum(arr, target):\\n    # Set to track cumulative sums, initialized with 0\\n    seen_sums = {0}\\n    current_sum = 0\\n    \\n    for num in arr:\\n        current_sum += num\\n        \\n        # If (current_sum - target) is in the set, a subarray exists\\n        if (current_sum - target) in seen_sums:\\n            return True\\n            \\n        seen_sums.add(current_sum)\\n        \\n    return False\\nAnalysis:\\n* Time Complexity: O(n) because we pass through the array once, and set lookups are O(1).\\n* Space Complexity: O(n) to store the cumulative sums in the set.', '[ANSWER_5_START]\\nQuestion 5\\nAnswer:\\nImpact of Network Latency and Bandwidth\\nIn distributed systems, network latency introduces delays in communication between nodes, directly\\naffecting the response time perceived by the user and the speed of data replication. Bandwidth\\nconstraints limit the volume of data that can be transmitted per unit of time. High latency can lead to\\nconsistency issues (stale data) if replication is slow, while low bandwidth can cause bottlenecks during\\nhigh-traffic periods.\\nArchitectural Strategies\\n1. Caching: Implementing aggressive caching strategies (e.g., Redis or CDNs) closer to the user to\\nreduce network calls.\\n2. Data Compression: Compressing data before transmission to optimize available pipe capacity.\\n3. Asynchronous Communication: Using message queues (like Kafka) so the UI remains responsive\\neven if backend synchronization is slow.\\n4. Local Processing (Edge Computing): Moving computation to the client side or edge servers to\\nreduce round-trip times.\\nTrade-offs\\nThese optimizations often come with trade-offs. For instance, aggressive caching can lead to eventual\\nconsistency rather than strong consistency. We accept that a user might see slightly outdated data\\n(Performance over Consistency) to ensure the system remains usable in a poor network environment.', '[ANSWER_6_START]\\nQuestion 6\\ndb.orders.aggregate([\\n    {\\n        $group: {\\n            _id: {\\n                category: \"$product.category\",\\n                month: { $dateToString: { format: \"%Y-%m\", date: \"$order_date\" } }\\n            },\\n            monthly_revenue: { $sum: \"$total_amount\" }\\n        }\\n    },\\n    {\\n        $sort: { monthly_revenue: -1 }\\n    }\\n])\\nExplanation:\\n1. $group: Groups documents by a composite ID containing both the product category and the\\nformatted month.\\n2. $sum: Calculates the total revenue for each group.\\n3. $sort: Orders the results by monthly_revenue in descending order (-1).']\n",
      "Total answers extracted: 6\n",
      "Q1 question_type raw = 'DESCRIPTIVE'\n",
      "Grading descriptive question...\n",
      "⚠️ LLM failed: Expecting value: line 1 column 1 (char 0)\n",
      "Generating embedding for 1 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generated successfully.\n",
      "Generating embedding for 1 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generated successfully.\n",
      "Q2 question_type raw = 'TECHNICAL'\n",
      "Generating embedding for 1 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generated successfully.\n",
      "Generating embedding for 1 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generated successfully.\n",
      "Generating embedding for 1 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generated successfully.\n",
      "Generating embedding for 1 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generated successfully.\n",
      "Generating embedding for 1 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generated successfully.\n",
      "Generating embedding for 1 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generated successfully.\n",
      "Generating embedding for 1 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generated successfully.\n",
      "Generating embedding for 1 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 11.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generated successfully.\n",
      "Generating embedding for 1 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generated successfully.\n",
      "Q3 question_type raw = 'DESCRIPTIVE'\n",
      "Grading descriptive question...\n",
      "⚠️ descriptive_config missing → semantic fallback\n",
      "Generating embedding for 1 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generated successfully.\n",
      "Generating embedding for 1 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generated successfully.\n",
      "Q4 question_type raw = 'TECHNICAL'\n",
      "Generating embedding for 1 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generated successfully.\n",
      "Generating embedding for 1 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generated successfully.\n",
      "Generating embedding for 1 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generated successfully.\n",
      "Generating embedding for 1 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generated successfully.\n",
      "Generating embedding for 1 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generated successfully.\n",
      "Generating embedding for 1 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generated successfully.\n",
      "Generating embedding for 1 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generated successfully.\n",
      "Generating embedding for 1 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generated successfully.\n",
      "Generating embedding for 1 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generated successfully.\n",
      "Generating embedding for 1 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generated successfully.\n",
      "Q5 question_type raw = 'DESCRIPTIVE'\n",
      "Grading descriptive question...\n",
      "⚠️ LLM failed: Expecting value: line 1 column 1 (char 0)\n",
      "Generating embedding for 1 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generated successfully.\n",
      "Generating embedding for 1 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generated successfully.\n",
      "Q6 question_type raw = 'TECHNICAL'\n",
      "Generating embedding for 1 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generated successfully.\n",
      "Generating embedding for 1 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generated successfully.\n",
      "Generating embedding for 1 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generated successfully.\n",
      "Generating embedding for 1 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generated successfully.\n",
      "Generating embedding for 1 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generated successfully.\n",
      "Generating embedding for 1 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generated successfully.\n",
      "Generating embedding for 1 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generated successfully.\n",
      "Generating embedding for 1 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generated successfully.\n",
      "Generating embedding for 1 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generated successfully.\n",
      "Generating embedding for 1 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generated successfully.\n",
      "[{'question_number': 1, 'marks_awarded': 4, 'max_marks': 10}, {'question_number': 2, 'marks_awarded': 5, 'max_marks': 8}, {'question_number': 3, 'marks_awarded': 7, 'max_marks': 12}, {'question_number': 4, 'marks_awarded': 4, 'max_marks': 7}, {'question_number': 5, 'marks_awarded': 5, 'max_marks': 9}, {'question_number': 6, 'marks_awarded': 3, 'max_marks': 6}]\n",
      "[{'question_number': 1, 'marks_awarded': 4, 'max_marks': 10}, {'question_number': 2, 'marks_awarded': 5, 'max_marks': 8}, {'question_number': 3, 'marks_awarded': 7, 'max_marks': 12}, {'question_number': 4, 'marks_awarded': 4, 'max_marks': 7}, {'question_number': 5, 'marks_awarded': 5, 'max_marks': 9}, {'question_number': 6, 'marks_awarded': 3, 'max_marks': 6}]\n",
      "[{'question_number': 1, 'marks_awarded': 4, 'max_marks': 10}, {'question_number': 2, 'marks_awarded': 5, 'max_marks': 8}, {'question_number': 3, 'marks_awarded': 7, 'max_marks': 12}, {'question_number': 4, 'marks_awarded': 4, 'max_marks': 7}, {'question_number': 5, 'marks_awarded': 5, 'max_marks': 9}, {'question_number': 6, 'marks_awarded': 3, 'max_marks': 6}]\n",
      "[{'question_number': 1, 'marks_awarded': 4, 'max_marks': 10}, {'question_number': 2, 'marks_awarded': 5, 'max_marks': 8}, {'question_number': 3, 'marks_awarded': 7, 'max_marks': 12}, {'question_number': 4, 'marks_awarded': 4, 'max_marks': 7}, {'question_number': 5, 'marks_awarded': 5, 'max_marks': 9}, {'question_number': 6, 'marks_awarded': 3, 'max_marks': 6}]\n",
      "[{'question_number': 1, 'marks_awarded': 4, 'max_marks': 10}, {'question_number': 2, 'marks_awarded': 5, 'max_marks': 8}, {'question_number': 3, 'marks_awarded': 7, 'max_marks': 12}, {'question_number': 4, 'marks_awarded': 4, 'max_marks': 7}, {'question_number': 5, 'marks_awarded': 5, 'max_marks': 9}, {'question_number': 6, 'marks_awarded': 3, 'max_marks': 6}]\n",
      "[{'question_number': 1, 'marks_awarded': 4, 'max_marks': 10}, {'question_number': 2, 'marks_awarded': 5, 'max_marks': 8}, {'question_number': 3, 'marks_awarded': 7, 'max_marks': 12}, {'question_number': 4, 'marks_awarded': 4, 'max_marks': 7}, {'question_number': 5, 'marks_awarded': 5, 'max_marks': 9}, {'question_number': 6, 'marks_awarded': 3, 'max_marks': 6}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "exam_id = \"CS_ADV_2025\"\n",
    "final_results = []\n",
    "\n",
    "answer_texts = extract_student_text(answer_file_path)\n",
    "print(\"Extracted student answers:\", answer_texts)\n",
    "print(f\"Total answers extracted: {len(answer_texts)}\") \n",
    "\n",
    "for i, student_answer in enumerate(answer_texts):\n",
    "    question_number = i + 1\n",
    "\n",
    "    question = fetch_question(exam_id, question_number)\n",
    "    print(\n",
    "        f\"Q{question_number} question_type raw = {repr(question['question_type'])}\"\n",
    "    )\n",
    "    if question is None:\n",
    "        continue\n",
    "\n",
    "    marks = 0\n",
    "    \n",
    "    if question[\"question_type\"] == \"TECHNICAL\":\n",
    "        tech = question[\"technical_config\"]\n",
    "        marks = grade_technical_question(\n",
    "            student_answer=student_answer,\n",
    "            technical_config=tech,\n",
    "            embedding_manager=embedding_manager,\n",
    "            max_marks=question[\"max_marks\"]\n",
    "    )\n",
    "\n",
    "\n",
    "    elif question[\"question_type\"] == \"DESCRIPTIVE\":\n",
    "        marks = grade_descriptive_question(question, student_answer, embedding_manager)\n",
    "\n",
    "    final_results.append({\n",
    "        \"question_number\": question_number,\n",
    "        \"marks_awarded\": marks,\n",
    "        \"max_marks\": question[\"max_marks\"]\n",
    "    })\n",
    "for i in final_results:\n",
    "    print(final_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf817d6",
   "metadata": {},
   "source": [
    "COSINE SIMILARITY FOR STUDENT ANSWER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03f03316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarity(\n",
    "    student_embeddings: np.ndarray,\n",
    "    reference_embeddings: np.ndarray\n",
    ") -> np.ndarray:\n",
    "    return cosine_similarity(student_embeddings, reference_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649785f8",
   "metadata": {},
   "source": [
    "GRADING ANSWERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f111bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_answers(\n",
    "    similarity_matrix: np.ndarray,\n",
    "    max_marks: int = 10\n",
    ") -> list[int]:\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    for i in range(len(similarity_matrix)):\n",
    "        sim = similarity_matrix[i][i] \n",
    "\n",
    "        if sim >= 0.85:\n",
    "            marks = max_marks\n",
    "        elif sim >= 0.70:\n",
    "            marks = int(0.7 * max_marks)\n",
    "        elif sim >= 0.50:\n",
    "            marks = int(0.4 * max_marks)\n",
    "        else:\n",
    "            marks = 0\n",
    "\n",
    "        scores.append(marks)\n",
    "\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab7e695",
   "metadata": {},
   "source": [
    "SAMPLE IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0c4c450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: all-MiniLM-L6-v2\n",
      "Embedding model loaded successfully.Embedding dimension: 384\n",
      "Generating embedding for 6 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generated successfully.\n",
      "Generating embedding for 6 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generated successfully.\n",
      "Similarity matrix:\n",
      " [[ 3.9327002e-01 -4.2582285e-03  4.3389931e-02 -6.7810401e-02\n",
      "   7.1838066e-02  8.7313883e-02]\n",
      " [-8.2793981e-02  8.1464076e-01 -3.4929711e-02  4.7338054e-02\n",
      "   4.8571780e-02  2.6686987e-01]\n",
      " [ 1.6020734e-02 -1.4208573e-01  6.6754258e-01 -1.7946105e-02\n",
      "  -9.4776250e-02  3.8414530e-02]\n",
      " [-2.0837912e-02 -6.9741458e-02  3.5219837e-02  5.3178853e-01\n",
      "   7.7400036e-02  8.5538082e-02]\n",
      " [ 1.5591764e-01 -5.4917157e-02 -6.9770478e-02 -2.7748611e-02\n",
      "   5.8341110e-01 -2.7397433e-02]\n",
      " [-7.3646575e-02  2.7191347e-01  1.7034076e-04  9.5546991e-02\n",
      "  -3.4243561e-02  6.2526649e-01]]\n",
      "Final scores: [0, 7, 4, 4, 4, 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Student answers (from your extractor)\n",
    "student_answers = extract_student_text(answer_file_path)\n",
    "\n",
    "# Reference answers (from answer key / MongoDB / file)\n",
    "reference_answers = [\n",
    "    \"ACID properties ensure atomicity, consistency, isolation, and durability...\",\n",
    "    \"SELECT department, AVG(salary) FROM employees GROUP BY department ORDER BY AVG(salary) DESC LIMIT 5;\",\n",
    "    \"Supervised learning uses labeled data while unsupervised learning does not...\",\n",
    "    \"Use a hash set to find the longest subarray in O(n) time...\",\n",
    "    \"Network latency affects throughput and response time...\",\n",
    "    \"db.orders.aggregate([...]) groups and filters documents...\"\n",
    "]\n",
    "\n",
    "embedding_manager = embeddingManager()\n",
    "\n",
    "# Generate embeddings\n",
    "student_embeddings = embedding_manager.generate_embeddings(student_answers)\n",
    "reference_embeddings = embedding_manager.generate_embeddings(reference_answers)\n",
    "\n",
    "# Compute similarity\n",
    "similarity_matrix = compute_cosine_similarity(\n",
    "    student_embeddings,\n",
    "    reference_embeddings\n",
    ")\n",
    "\n",
    "# Grade\n",
    "scores = grade_answers(similarity_matrix)\n",
    "\n",
    "print(\"Similarity matrix:\\n\", similarity_matrix)\n",
    "print(\"Final scores:\", scores)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
